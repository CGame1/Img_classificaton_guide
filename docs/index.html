<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Image Classification Guide</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 700px;
            margin: 40px auto;
            padding: 20px;
            line-height: 1.6;
        }
        .button {
            display: inline-block;
            margin-top: 20px;
        }
        .button img {
            height: 40px;
        }
    </style>
</head>
<body>

    <h1>Image Classification Guide</h1>   


    <footer style="margin-top: 40px; font-size: 0.9em; color: #555;">
    <p><strong>Authors:</strong> Dr. Chloe Game (<a href="https://github.com/CGame1">CGame1</a>), University of Bergen (UiB)&nbsp;| Dr. Nils Piechaud (<a href="https://github.com/Npiechaud">Npiechaud</a>), Institute of Marine Research (IMR)&nbsp; </p>
</footer>



   <hr>

    <p>Welcome! This page provides access to Jupyter notebooks that demonstrates how to (1) implement <a href="https://colab.research.google.com/github/CGame1/Img_classificaton_guide/blob/main/notebooks/CrossVal_with_Yolo.ipynb">cross-validation with YOLO</a>
         for image classification in Python and (2) <a href="https://colab.research.google.com/github/CGame1/Img_classificaton_guide/blob/main/notebooks/Yolo_classifier_deployment_colab.ipynb"
">deploy a trained YOLO model</a>, from <a href="https://huggingface.co/">Hugging Face</a> for example, on new images üì∑üåäüêôü§ñ
</p> 
 


 <p>These are designed to be beginner-friendly, with the option to run them entirely online using Google Colab 
    ‚Äî no installation or GPU required. However, if you're more comfortable with Python and Jupyter, you can also clone the <a href="https://github.com/CGame1/Img_classificaton_guide">repository</a> and run it locally. 
</p>



<p>  <strong>No data is required</strong>, as the code also downloads an open-source <a href="https://huggingface.co/datasets/CGame1/schulz_bank_biotopes">dataset</a>
      from Hugging Face. 
      Note that this is a copy of the original <a href="https://doi.pangaea.de/10.1594/PANGAEA.949920">dataset</a> (for faster access), 
      see <a href="https://www.sciencedirect.com/science/article/pii/S0967063722002333#da0010">Meyer et al., 2023</a> for details.
</p>


<p>This resource is a supplement to our paper: <strong><em>Deep Blueprint: A Literature Review and Guide to Automated Image Classification for Ecologists</em>
 </strong> (see below).
</p>

<p><strong>For R users</strong>: A shiny app (and associated R code) is also available <a href="https://github.com/Npiechaud/Benthic-Images-CV/tree/main/shiny_app">here</a> 
for select tasks.
</p>


<figure style="text-align: center; margin: 30px 0;">
    <img src="https://github.com/CGame1/Img_classificaton_guide/blob/main/docs/workflow.png?raw=true"
         alt="Classification workflow" 
         style="max-width: 100%; height: auto; border: 1px solid #ccc; border-radius: 8px;">
    <figcaption style="margin-top: 10px; font-size: 0.9em; color: #555;">
       Figure 1: Simplified and idealized diagram of an image classification scenario. Each box represents a key task and corresponds to a section of the paper to aid comprehension.  While presented largely linearly for clarity, real-world ML workflows are often iterative and non-linear and the need to revisit specific sections may vary depending on the scenario.
    </figcaption>
</figure>

<hr>
<h2>üìö How to Cite This Work</h2>

<p>If you use this code, please cite our  <strong>preprint</strong> :</p>

<blockquote style="background-color: #f9f9f9; border-left: 4px solid #ccc; padding: 10px; font-style: italic;">
    Your Name, Another Author, and Third Author. <strong>‚ÄúTitle of the Paper.‚Äù</strong> Journal Name, vol. XX, no. X, Year, pp. XX‚ÄìXX. DOI: <a href="https://doi.org/your-doi">https://doi.org/your-doi</a>.
    Game, C.A., Piechaud, N. and Howell, K.L. (2025)  <strong>‚ÄúDeep Blueprint: A Literature Review and Guide to Automated Image Classification for Ecologists‚Äù</strong>, bioRxiv, p. 2025.11.03.686223. Available at:  <a https://doi.org/10.1101/2025.11.03.686223](https://doi.org/10.1101/2025.11.03.686223)</a>. 

</blockquote>

<p>Or use the following BibTeX entry:</p>



<pre style="background-color: #f4f4f4; padding: 10px; border-radius: 5px; overflow-x: auto;">

@article {Game2025.11.03.686223,
	author = {Game, Chloe A. and Piechaud, Nils and Howell, Kerry L.},
	title = {Deep Blueprint: A Literature Review and Guide to Automated Image Classification for Ecologists},
	elocation-id = {2025.11.03.686223},
	year = {2025},
	doi = {10.1101/2025.11.03.686223},
	publisher = {Cold Spring Harbor Laboratory},
	URL = {https://www.biorxiv.org/content/early/2025/11/04/2025.11.03.686223},
	eprint = {https://www.biorxiv.org/content/early/2025/11/04/2025.11.03.686223.full.pdf},
	journal = {bioRxiv}
}
    
</pre>

